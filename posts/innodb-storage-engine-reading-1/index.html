<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>《MySQL 技术内幕-InnoDB 存储引擎》阅读小记（一） | Chyroc的博客</title><link rel=stylesheet href=/css/style.css><link href=//cdn.bootcss.com/highlight.js/9.12.0/styles/github.min.css rel=stylesheet></head><body><nav><ul class=menu><li><a href=/>主页</a></li><li><a href=/blogroll/>友链</a></li><li><a href=/about/>关于</a></li></ul><hr></nav><div class=article-meta><h1><span class=title>《MySQL 技术内幕-InnoDB 存储引擎》阅读小记（一）</span></h1><h2 class=date>2018/09/05</h2></div><main><p>[TOC]</p><h1 id=mysql-体系结构>MySQL 体系结构</h1><p><img src=https://media.chyroc.cn/img/mysql.png alt></p><h1 id=innodb-存储引擎>InnoDB 存储引擎</h1><h2 id=概述>概述</h2><ul><li>从 mysql 5.5 版本开始是默认引擎</li><li>第一个完整支持 ACID 事务的 MySQL 引擎</li><li>特点：行锁设计、支持 MVCC、支持外键、提供一致性非锁定读、有效利用内存和 CPU</li></ul><h2 id=体系架构>体系架构</h2><p><img src=https://media.chyroc.cn/img/innodb.png alt></p><h3 id=后台线程>后台线程</h3><ul><li><p>innodb 存储引擎是多线程模型，有多个不同的后台线程，负责处理不同的任务</p></li><li><p>master thread：将缓冲池的数据异步刷新到磁盘，保证数据的一致性，包括脏页的刷新、合并插入缓冲（insert buffer）、UNDO 页的回收</p></li><li><p>io thread</p><ul><li>innodb 大量使用了 AIO(async io)处理 io 请求，极大提高了数据库的性能</li><li>io thread 的工作主要是负责这些 io 请求的回调处理</li><li>1.0 版本之前共有 4 个 io thread：write，read，insert buffer，log</li><li>1.0 之后，rread 和 write thread 分别增大到了 4 个</li><li>1.0 之后，可以分别使用 innodb_read_io_threads 和 innodb_write_io_threads 设置线程数</li></ul></li><li><p>purge thread</p><ul><li><p>事务提交后，锁使用的 undolog 可能不再需要，所以需要 purge thread 回收已经使用并且分配的 undo 页</p></li><li><p>1.1 之前，purge 操作在 master thread 内完成</p></li><li><p>1.1 之后，purge 可以独立到单独的线程，减轻 master thread 工作，提高 cpu 利用率和提高性能</p></li><li><p>添加下面的配置 开启独立的 purge thread</p></li><li><pre><code class=language-ini>[mysqld]
innodb_purge_threads=1
</code></pre></li><li><p>1.1 只支持设置 innodb_purge_threads=1，1.1 之后才支持设置多个</p></li><li><p>page cleaner thread</p></li><li><p>1.2.x 版本引入</p></li><li><p>将之前版本的脏页的刷新操作都放入单独的线程中</p></li><li><p>减轻 master thread 的工作和对用户查询线程的阻塞，提高性能</p></li></ul><h3 id=内存>内存</h3><h4 id=缓冲池>缓冲池</h4><p>innodb 是基础磁盘存储的，将记录按照页的方式进行管理，是基础磁盘的数据库系统（disk-base database）</p><p>所以用缓冲池技术提高数据库的整体性能</p><ul><li>读</li><li>读取页的时候，将磁盘的页放在缓冲池中，这个过程称之为将也<code>FIX</code>在缓冲池中</li><li>然后下一次读相同的页的时候，首先判断是不是在缓冲池里面</li><li>是的话，直接读取该页，否则读磁盘</li><li>写</li><li>先修改缓冲池中的页</li><li>然后以一定的频率刷新到磁盘</li><li>注意不是每次数据修改都刷新，而是通过<code>Checkpoint</code> 机制刷新会磁盘</li></ul><p>所以缓冲池的大小影响数据库的整体性能</p><ul><li>32 为操作系统限制，只能设置为 3G；可以打开 PAE 选项获得最大 64G 的内存</li><li>建议数据库系统都采用 64 位操作系统</li><li>可以通过配置 innodb_bufer_pool_size 设置</li></ul><p>innodb 内存数据对象</p><p><img src=https://media.chyroc.cn/img/innodb-memory.png alt></p><p>从 1.0.x 开始，可以有多个缓冲池实例，每个页根据哈希值平均分配到不同的缓冲池实例，可以通过 innodb_buffer_pool_instances 设置，默认为 1</p><h4 id=lru-list-free-list-flush-list>LRU list / Free list / Flush list</h4><p>缓冲池通过 LRU（lastest recent used ， 最近最少使用）算法进行管理：最先释放最不经常使用的数据</p><p>innodb 对 lru 算法进行了一个优化：将新数据不放在首部，而是中间部位 midpoint 位置：扫描的时候读了一次数据就再也不用了，避免热点数据排除 lru list。</p><p>这个算法叫做 midpoint insertion strategy，midpoint 位置由参数 innodb_old_blocks_pct 控制，默认是 lru list 的 <sup>5</sup>&frasl;<sub>8</sub> 处。</p><p>midpoint 之后的 list 叫做 old list，之前的 list 叫做 new list。</p><h2 id=checkpoint-技术>Checkpoint 技术</h2><p>做的什么事情</p><ul><li>将缓冲池的脏页刷回到磁盘</li><li>重点在于：每次刷新多少页到磁盘，每次从哪里取脏数据，什么时间触发 checkpoint</li></ul><p>解决下面几个问题</p><ul><li>缩短数据库的恢复时间：checkpoint 之前的数据都已经刷到磁盘，只需要回复 checkpoint 之后的数据</li><li>缓冲池不够用的时候，将脏页刷新到磁盘：将 lru 算法溢出的数据，如果是脏页，刷回磁盘</li><li>重做日志不可用的时候，刷新脏页：？？？</li></ul><p>innodb 存储引擎使用 LSN（log sequence number）标记版本，是一个 8 字节的数字，单位是字节。</p><p>每个页有 LSN，重做日志也有 LSN，checkpoint 也有 LSN</p><p>checkpoint 发生的时间、条件、脏页的选择等都非常复杂</p><p>innodb 内部有两种 checkpoint</p><ul><li><p>sharp checkpoint：数据库关闭的时候将所有的脏页刷回到磁盘，默认方式，参数 innodb_fast_shudown=1</p></li><li><p>fuzzy checkpoint</p></li><li><p>master thread checkpoint：master thread 异步的以每秒或者每 10 秒的速度从缓冲池的脏页列表中刷新一定比列的也回磁盘</p></li><li><p>flush_lru_list checkpoint：innodb 需要保证 lru list 中有 100 个空闲页可使用，如果没有这么多，就会将 lru list 尾部的页移除。如果这些页有脏页，就需要进行 checkpoint（在 1.2.x 开始，这些在一个单独的 page cleaner 线程中）</p></li><li><p>async/sync flush checkpoint：？？？</p></li><li><p>dirty page too much checkpoint：脏页太多，导致 innodb 强制进行 checkpoint，为了保证缓冲池有足够的页。由 innodb_max_dirty_pages_pct 控制，假设为 75（1.0.x 之后的默认值），那么缓冲池中脏页数据占据 75%的时候，就会强制 checkpoint。</p></li></ul><h2 id=master-thread-工作方式>master thread 工作方式</h2><p>主要工作都是在这里完成的</p><h3 id=innodb-1-0-x-之间版本的-master-thread>innodb 1.0.x 之间版本的 master thread</h3><p>Master thread 内部有多个循环 loop 组成：</p><ul><li>主循环 loop</li><li>后台循环 backgroup loop</li><li>刷新循环 flush loop</li><li>暂停循环 suspend loop</li></ul><h4 id=主循环-loop>主循环 loop</h4><p>在主循环里面会有一个每秒进行的操作和一个每 10 秒进行的操作</p><p>每秒进行的操作：</p><ul><li>日志缓冲刷新到磁盘，即使事务还没有提交（总是）：所以再大的事务提交也很快</li><li>合并插入缓冲（insert buffer）（可能）：判断前一秒发生的 IO 次数，如果小于 5，认为当前 IO 压力很小，可以执行本操作</li><li>之多刷新 100 个 innodb 的缓冲池的脏页到磁盘（可能）：判断当前缓冲池里面的脏页的比例是否超过了配置值（默认 90，90%），超过了阈值，就会将 100 个在脏页数据写入磁盘</li><li>如果当前没有用户活动，切换到 backgroup loop（可能)</li></ul><p>每 10 秒进行的操作：</p><ul><li>刷新 100 个脏页到磁盘（可能）：判断过去 10 秒发送的 IO 次数，如果小于 200，认为压力比较小，执行本操作</li><li>合并至多 5 个插入缓冲（总是）：然后执行这个</li><li>将日志缓冲刷新到磁盘（总是）：然后执行这个</li><li>删除无用的 undo 页（总是）：执行 full purge 操作（每次最多尝试回收 20 个 undo 页）</li><li>刷新 100 个或者 10 个脏页到磁盘（总是）：如果脏页比例超过 70%，就刷新 100 个，否则是 10 个脏页会磁盘</li></ul><h4 id=backgroup-loop>Backgroup loop</h4><p>如果没有用户活动或者数据库关闭（shutdown）就会切换到这个线程</p><p>执行以下操作：</p><ul><li>删除无用的 undo 页（总是）</li><li>合并 20 个插入缓冲（总是）</li><li>跳回到主循环（总是）</li><li>不断刷新 100 个页直到符合条件（可能，跳转到 flush loop 中完成，如果 flush loop 中也没什么可做的，就会切换到 suspend loop，将 master thread 挂起，等待事件）</li></ul><h3 id=innodb-1-2-x-之前版本的-master-thread>Innodb 1.2.x 之前版本的 master thread</h3><p>刷新数量不再硬编码，而是使用百分比控制</p><ul><li>在合并插入缓冲的时候，合并插入缓冲的数量为 innodb_io_capacity 的 5%</li><li>在从缓冲区刷新脏页的时候，刷新脏页的数量为 innodb_io_capacity</li></ul><p>当使用 ssd 之类的时候，就可以调高 innodb_io_capacity，知道符合磁盘 IO 的吞吐量</p><p>将 innodb_max_dirty_pages_pct 从 90 调整到 80</p><p>略</p><h3 id=innodb-1-2-x-版本的-master-thread>innodb 1.2.x 版本的 master thread</h3><p>略</p><h2 id=innodb-的关键特性>innodb 的关键特性</h2><p>包括</p><ul><li>插入缓冲 insert buffer</li><li>两次写 double write</li><li>自适应哈希索引 adaptive hash index</li><li>异步 io async io</li><li>刷新邻接页 flush neighbor page</li></ul><h3 id=缓冲插入-insert-buffer>缓冲插入 insert buffer</h3><p>带给 innodb 的是性能的提升</p><h4 id=1-insert-buffer>1. insert buffer</h4><p>缓冲池里面有 insert buffer，<strong>物理页里面也有</strong></p><p>在 innodb 中，主键是唯一的标识符。插入的时候会寻找到主键的位置，然后插入。</p><p>所以如果主键是逐渐递增的，那么就是磁盘的顺序 IO，速度很快。</p><p>但是在一个表不会只有一个主键，可能还有其他索引，那么在 B+树的叶子节点上，就要寻找到第二个索引所在的位置进行插入，也就是随机 IO。</p><p>为了优化这种随机 IO，创建了 insert buffer：先判断插入的索引页是不是在缓冲池，如果是，就插入到缓冲池；如果不是，就先放到一个 insert buffer 中。然后再以一定的频率和情况将 insert buffer 和所以也子节点 merge。这个时候通常能够将多个插入合并到一个操作里面（因为在一个索引页），大大提高了非聚集索引插入的性能。</p><p>insert buffer 的使用需要同时满足以下两个条件：</p><ul><li>索引是辅助索引 secondary index</li><li>索引不是唯一 unique 的：如果是唯一的，就需要先读一遍（随机读）看看是不是已经存在，就会失去意义</li></ul><p>insert buffer 的问题</p><h4 id=2-change-buffer>2. change buffer</h4><p>1.0.x 引入了 change buffer，可视为 insert buffer 的升级，可以对 dml 操作都进行缓冲，分别是：</p><ul><li>insert buffer</li><li>delete buffer</li><li>purge buffer</li></ul><p>同样有<strong>非唯一</strong>的限制</p><p>对一个记录进行 update 操作有两个过程</p><ul><li>将记录标记为删除：delete buffer</li><li>将记录真正删除：pruge buffer</li></ul><p>提供 innodb_change_buffering 参数，用来控制开启哪种 buffer</p><ul><li>inserts</li><li>deletes</li><li>purges</li><li>changes：开启 inserts 和 deletes</li><li>all：都开启</li><li>node：都不开启</li></ul><h4 id=3-insert-buffer-的内部实现>3. Insert buffer 的内部实现</h4><p>insert buffer 是一个全局的放在共享空间的 B+树</p><ul><li>叶子节点</li><li>非叶子节点</li></ul><p>？？？</p><h4 id=4-merge-isnert-buffer>4. merge isnert buffer</h4><p>什么时候将 insert buffer 的数据 merge 到辅助索引页</p><ul><li>辅助索引页被读取到缓冲池的时候：读这页的时候，看看这页有没有数据在 insert buffer，如果有的就写到辅助索引页</li><li>insert buffer bitmap 追踪到该辅助索引页已经没有可用空间的时候：insert buffer bitmap 记录每个辅助索引页的可用空间，如果可用空间少于 <sup>1</sup>&frasl;<sub>32</sub> 页，那么就会强制把 insert buffer 的数据写到辅助索引页</li><li>master thread：每秒、每 10 秒会进行 merge insert buffer（不止一个页）？？？</li></ul><h3 id=两次写-double-write>两次写 double write</h3><p>带给 innodb 的是数据页的可靠性</p><p>假如写输入到一个页中，写到一半，发生宕机（部分写失效 partial page write），导致页损坏，那么可能会导致数据丢失。这个是不能通过重做日志恢复，因为页本身已经损坏，重做日志（对页的物理操作）没有意义。</p><p>需要先通过页的副本还原该页，再使用重做日志，这个叫做 doublewrite。</p><p><img src=https://media.chyroc.cn/img/innodb-doublewrite.png alt></p><p>？？？？？？</p><h3 id=自适应哈希索引-adaptive-hash-index>自适应哈希索引 adaptive hash index</h3><p>哈希：一次就可以定位数据</p><p>B+树：取决于树的高度，生产环境一般是 3-4 层，所以需要查询 3-4 次</p><p>AHI（adaptive hash index）：观察到一个访问模式访问频繁，就会建立哈希索引</p><ul><li>通过该模式访问了 100 次（模式：where x = ?）</li><li>页通过该模式访问了 N 次，其中 N = 页的记录 * <sup>1</sup>&frasl;<sub>16</sub></li></ul><h3 id=异步-io-async-io>异步 IO async io</h3><h3 id=刷新邻接页-flush-neighbor-page>刷新邻接页 flush neighbor page</h3><p>刷新一个脏页的时候，检测这个页所在的区（extent）的所有页，如果是脏页，就一起刷新。</p><p>所以可以利用 AIO 将多个 io 合并为一个 io</p><p>问题</p><ul><li>如果将一个页不怎么脏的写入了，那么之后又会很快变脏？</li><li>固态硬盘有很高的 IOPS，是不是还需要？（1.2.x 可以关闭本功能）</li></ul></li></ul></main><footer><script async src="//cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><script src=../../js/jquery-3.3.1.min.js></script><script src=../../js/code.js></script><script src=../../css/highlight.css></script><script src=../../js/instantclick.min.js data-no-instant></script><script data-no-instant>InstantClick.init();</script><script>hljs.configure({languages:[]});hljs.initHighlightingOnLoad();</script><hr>&copy; <a href=https://chyroc.cn>chyroc</a> <a href=https://themes.gohugo.io/hugo-xmin/>Theme By hyde</a> 2021
<span id=reading-statistics><span></footer><div id=git-comments></div><link rel=stylesheet href=https://imsun.github.io/gitment/style/default.css><script src=https://imsun.github.io/gitment/dist/gitment.browser.js></script><script>var gitment=new Gitment({id:'innodb-storage-engine-reading-1',title:'《MySQL 技术内幕-InnoDB 存储引擎》阅读小记（一）',owner:'Chyroc',repo:'chyroc.github.io',oauth:{client_id:'36628d87f0ace3c0f34c',client_secret:'814e29f878a31ddf2a0f8f010c2bc3615750a998',}})
gitment.render('git-comments')</script></body></html>